---
title: "Uniform sampling across the whole territory without any cells"
output: pdf_document
date: "2024-06-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("kableExtra")
```

```{r}
library(readxl) # to read the initial file
library(magrittr) # for pipes
library(tibble) # for add_column and tibble
library(kableExtra) # To have LaTeX tables based on dataframes
```

# Preliminaries

We do not need the artificial forest for now. We just need a virtual 1000x1000 square.

```{r}
# Sample size
n <- 1000
```

```{r}
# Marginal density: density of the uniform distribution over 1:1000
# Which leads us to the inclusion density function
p <- sum(rep((1/1000)*(1/1000), n))
p
# p may be considered simply as a numeric
# since the inclusion density function is constant in this case
# Otherwise, we would need a vector
```

# Estimates with simple functions and one sample

We are looking for estimates of totals over the whole territory, i.e. double integrals of some functions.
To make such estimations, we begin with one single sample (made by uniform sampling).

## Creating one sample

```{r}
# Dataframe to contain all coordinates of n randomly chosen points in a 1000x1000 square
random_points <- data.frame(x = rep(0, n), y = rep(0, n))
```

```{r}
# Uniform sampling over the whole territory
random_points$x <- runif(n, 0, 1000)
random_points$y <- runif(n, 0, 1000)
```

## First function: (x,y) $\mapsto$ 1

```{r}
## The most simple function
f_1 <- function(x,y){
  1
}
```

```{r}
# 1 given to each sampled point
random_points$rho1 <- rep(1, n)
```

```{r}
# Value to estimate: the area of the territory
area <- 1000*1000
```

```{r}
# Estimated value
# Formula given in Cordy (1993), page 3
est_area <- sum((random_points$rho1)/p) 
# Equal to 1e+06 whatever the chosen points
```

```{r}
# Conclusion
cat("Total à estimer :", area, "\nEstimation :", est_area)
```

## Second function: (x,y) $\mapsto$ as.numeric(x>y)

```{r}
## Indicator of (x>y)
f_ind <- function(x,y){
  as.numeric(x > y)
}
```

```{r}
# Value to estimate
half_area <- 1000*1000/2
```

```{r}
# 1 given to each sampled point that satisfies x>y
random_points$rho2 <- f_ind(random_points$x,random_points$y)
```

```{r}
# Estimated value
est_ind <- sum((random_points$rho2)/p)
# 492000 e.g.
```

```{r}
# Conclusion
cat("Total à estimer :", half_area, "\nEstimation :", est_ind)
```

## Third function: (x,y) $\mapsto$ x

```{r}
# x given to each point
f_x <- function(x,y){
  x
}
```

```{r}
# Value to estimate
val_x <- 500000000
```

```{r}
# Estimated value
est_x <- sum((random_points$x)/p)
# 490781983 e.g.
```

```{r}
# Conclusion
cat("Total à estimer :", val_x, "\nEstimation :", est_x)
```

# Variances with simple functions and one sample

Variance formulas for the uniform case are based on the formulas given by Cordy (1993), theorem 2 page 5 combined with the inclusion density given for example 1 page 4, which gives a simplified formula for this particular case.

## Case of the area

```{r}
# New variable: rho1^2
random_points$carre <- (random_points$rho1)^2
est_carre <- sum((random_points$carre)/p)
# est_carre = est_area # Logical since rho1 = carre = 1
```

```{r}
var_area <- ((1000*1000)/(n-1))*est_carre - (1/(n-1))*(est_area^2)
# The variance estimation is null as expected
```

```{r}
# f_1(x,y)^2 = f_1(x,y)
varTHEO_area <- area/p - (1/n)*(area^2)
# The theoretical variance is null as expected
# Since the total is equal to the area
```

```{r}
# Conclusion
cat("Variance théorique :", varTHEO_area, "\nEstimation de la variance :", var_area)
```

## Case of half of the area

```{r}
var_ind <- ((1000*1000)/(n-1))*est_ind - (1/(n-1))*(est_ind^2)
# Variance estimation: 250186186 e.g.
```

```{r}
# f_ind(x,y)^2 = f_ind(x,y)
varTHEO_ind <- half_area/p - (1/n)*(half_area^2)
# Theoretical variance: 2.5e+08, i.e. around 250186186
# Close to the empirical one
```

$V[\hat{\tau}_{y\pi}(S)] = \frac{n}{A} \times \frac{A}{2} - \frac{1}{n} \times (\frac{A}{2})^{2} $

```{r}
# Conclusion
cat("Variance théorique :", varTHEO_ind, "\nEstimation de la variance :", var_ind)
```

## Case of the function that keeps x

```{r}
f_x2 <- function(x,y){
  x^2
}
```

```{r}
# Value to estimate for this new function
val_x2 <- (10^12)/3
# Estimated value
est_x2 <- sum(((random_points$x)^2)/p)
# 499690876 e.g.
```

```{r}
var_x <- ((1000*1000)/(n-1))*est_x2 - (1/(n-1))*(est_x^2)
# Variance estimation: 8.341029e+13
```

```{r}
varTHEO_x <- val_x2/p - (1/n)*(val_x^2)
# Theoretical variance: 8.333333e+13, i.e. around 8.341029e+13
# Close to the estimated one
```

```{r}
# Conclusion
cat("Variance théorique :", varTHEO_x, "\nEstimation de la variance :", var_x)
```

# Monte Carlo

## First MC application step by step with the function that keeps x

```{r}
# Number of replications for the Monte-Carlo method
B <- 1000
```

```{r}
# Initialization with a first sample
series_MC <- data.frame(x.1 = runif(n, 0, 1000), y.1 = runif(n, 0, 1000))
col_names <- c("x1", "y1")
```

```{r}
# Making as many samples as necessary for MC (i.e. B)
for (b in 2:B) {
  x <- paste("x", b, sep = "")
  y <- paste("y", b, sep = "")
  # Uniform sampling over the whole territory
  a1 <- runif(n, 0, 1000)
  a2 <- runif(n, 0, 1000)
  series_MC <- series_MC %>% add_column(x = a1, y = a2)
  col_names <- append(col_names, c(x, y))
}
colnames(series_MC) <- col_names
```

```{r}
rm(a1, a2, x, y, b, col_names) # Useless now
```

```{r}
# Calculation of rho function for each pair (x,y)
rho_MC <- data.frame(x.1 = rep(0, n), y.1 = rep(0, n))
col_names <- c()
```

```{r}
for (c in 1:B) {
  col_ <- paste("est", c, sep = "")
  # With f_x
  a <- f_x(series_MC[(2*c)-1],series_MC[2*c])
  rho_MC <- rho_MC %>% add_column(col_ = a)
  col_names <- append(col_names, col_)
}
rho_MC$x.1 <- NULL
rho_MC$y.1 <- NULL
colnames(rho_MC) <- col_names
```

```{r}
rm(a, c, col_, col_names) # Useless now
```

```{r}
# List of estimated totals thus obtained from each sample
est_MC <- c()
```

```{r}
for (c in 1:B) {
  est_tot <- sum((rho_MC[c])/p)
  est_MC <- append(est_MC, est_tot)
}
```

```{r}
rm(c, est_tot) # Useless now
```

```{r}
# Empirical mean based on MC
cat("Total à estimer :", val_x, "\nMoyenne des estimations obtenues :", mean(est_MC)) 
# should be close to 5e+08
# 500182431 e.g.
```

```{r}
# Variance estimation based on MC
cat("Theoretical variance:", varTHEO_x, "\nVariance associée aux échantillons de Monte Carlo :", var(est_MC))
# 8.512412e+13 e.g.
```

## Automation of the MC method with a function

```{r}
### Function to automate Monte Carlo method

true_vs_MC <- function(n, B, f){
  # n: sample size; B: number of iterations for MC; 
  # f: function to consider (with 2 variables, x and y)
  p <- sum(rep((1/1000)*(1/1000), n))
  
  # 1st step: generating n samples
  series_MC <- data.frame(x.1 = runif(n, 0, 1000), y.1 = runif(n, 0, 1000))
  col_names <- c("x1", "y1")
  for (b in 2:B) {
    x <- paste("x", b, sep = "")
    y <- paste("y", b, sep = "")
    # Uniform sampling over the whole territory
    a1 <- runif(n, 0, 1000)
    a2 <- runif(n, 0, 1000)
    series_MC <- series_MC %>% add_column(x = a1, y = a2)
    col_names <- append(col_names, c(x, y))
  }
  colnames(series_MC) <- col_names
  
  # 2nd step: creating the values corresponding to the function
  rho_MC <- tibble(.rows = n)
  col_names <- c()
  for (c in 1:B) {
    col_ <- paste("est", c, sep = "")
    a <- f(series_MC[(2*c)-1],series_MC[2*c])
    rho_MC <- rho_MC %>% add_column(col_ = a)
    col_names <- append(col_names, col_)
    colnames(rho_MC) <- col_names
  }
  colnames(rho_MC) <- col_names
  
  # 3rd step: List of estimated totals thus obtained from each sample
  est_MC <- c()
  for (c in 1:B) {
    est_MC <- append(est_MC, sum((rho_MC[c])/p))
  }
  
  return(c(mean(est_MC), var(est_MC)))
  # Estimated value and Monte-Carlo variance
}
```

```{r}
res1 <- true_vs_MC(n = 1000, B = 1000, f = f_1)
cat("True integral:", 1e+06, "\nMean of all the estimations:", res1[1])
cat("\n\nTheoretical variance:", varTHEO_area, "\nMonte-Carlo variance:", res1[2])
# Totals: 1e+06 and 1e+06 (Equality as always)
# Variances: 0 and 0 (Equality as always)
```

```{r}
res2 <- true_vs_MC(n = 1000, B = 1000, f = f_ind)
cat("True integral:", 500000, "\nMean of all the estimations:", res2[1])
cat("\n\nTheoretical variance:", varTHEO_ind, "\nMonte-Carlo variance:", res2[2])
# Ex:
# True integral: 5e+05 
# Mean of all the estimations: 499214

# Theoretical variance: 2.5e+08 
# Monte-Carlo variance: 245287491
```

```{r}
res3 <- true_vs_MC(n = 1000, B = 1000, f = f_x)
cat("True integral:", 5e+08, "\nMean of all the estimations:", res3[1])
cat("\n\nTheoretical variance:", varTHEO_x, "\nMonte-Carlo variance:", res3[2])
# Ex:
# True integral: 5e+08 
# Mean of all the estimations: 499874718

# Theoretical variance: 8.333333e+13 
# Monte-Carlo variance: 7.99389e+13
```
# Nice table

```{r}
# Theoretical variances and values
VAR_theo <- c(varTHEO_area, varTHEO_ind, varTHEO_x)
VAL_theo <- c(area, half_area, val_x)
THEO_df <- as.data.frame(cbind(VAL_theo, VAR_theo))
```

```{r}
RES_df <- as.data.frame(rbind(res1,res2,res3))
```

```{r}
# `Parameter of interest` = fct_names, 

# Table for comparison
diff_var <- data.frame(`Difference between totals` = paste0(round(mapply(function(x,y){unlist(100*(y-x)/x)}, unlist(THEO_df[1]), unlist(RES_df[1])), digits = 3), "%"), `Difference between variances` = paste0(round(mapply(function(x,y){unlist(100*(y-x)/x)}, unlist(THEO_df[2]), unlist(RES_df[2])), digits = 3), "%") )
# diff_var <- ifelse(diff_var == "NaN%", 0, diff_var)
diff_var[diff_var == "NaN%"] <- "0%"
```

```{r}
tab_var <- diff_var %>%
  kable("latex", booktabs = FALSE, align = "cc", linesep = c("", "", "",
  "\\addlinespace"), caption = paste("Assessment of the efficiency with samples with size 1000 and 1000 Monte Carlo iterations"), col.names = gsub("[.]", " ", names(diff_var))) %>%
  kable_styling(latex_options = "hold_position") %>%
  row_spec(0, bold = TRUE) %>% # , hline_after = TRUE
  collapse_rows(columns = 1, latex_hline = "major")
```

```{r}
# The table itself
tab_var
```

```{r}
# The code that produced the table
cat(tab_var)
```


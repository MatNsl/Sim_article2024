---
title: "Draft"
output: html_document
date: "2024-06-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Tessellation ----------

```{r}
# Load necessary library
library(ggplot2)

# Define the size of the square space
space_size <- 10

# Define the size of the smaller squares
square_size <- 1

# Create a data frame to store the coordinates of the squares
squares <- data.frame(
  x = rep(seq(0, space_size - square_size, by = square_size), each = space_size / square_size),
  y = rep(seq(0, space_size - square_size, by = square_size), times = space_size / square_size)
)

# Plot the tessellation
ggplot() +
  geom_tile(data = squares, aes(x = x, y = y), width = square_size, height = square_size, fill = "lightblue", color = "black") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Square Tessellation", x = "X", y = "Y")
```

## Draft ----------

```{r}
# Tests (preliminaries)

# trees$cell2 <- 1*as.numeric((trees$x %in% seq(200, 300, by = .01)) & (trees$y %in% seq(200, 300, by = .01))) # Problem with 107th tree e.g.
# trees$cell <- 1*as.numeric((200 <= trees$x) & (trees$x < 300) & (200 <= trees$y) & (trees$y < 300))

# trees[trees$cell == 1 & trees$cell2 == 0,]
# Where is the pb?
# 297.21 %in% seq(233, 300, by = .01) # FALSE, idem for numbers below 233
# 297.21 %in% seq(234, 300, by = .01) # TRUE, idem for numbers above 234
```

```{r}
# Un peu long

# PROBLEME: ne garde que le 8 (i.e. le dernier nb)

trees$cell <- rep(0, 30942) # Initialisation de la variable

for (nb in 1:10){ # All the categories (to identify the cells)
for (ligne in 0:599){ # All the lines (en parcourant par rapport aux ordonnées)
  for(c in 1:60){ # En parcourant sur une même ligne
    # if (trees$cell == 0)
    trees$cell <- ifelse(
    # (trees$cell == 0) & 
      (vec[(nb-1)*60 + 1] <= trees$x) & (trees$x < vec[(nb-1)*60 + 1]+1) & (200+ligne <= trees$y) & (trees$y < 200+ligne+1), 
    list[nb], trees$cell)
  }

}
}

# (ligne-1)*trend + 
# (ligne-1)*trend + 
```


```{r}
# Un peu long

# PROBLEME: ne garde que le 8 (i.e. le dernier nb)

trees$cell <- rep(0, 30942) # Initialisation de la variable


for (ligne in 0:599){ # All the lines (en parcourant par rapport aux ordonnées)
  # for(c in 1:60){ # En parcourant sur une même ligne
    for (nb in 1:10){ # All the categories (to identify the cells)
    # if (trees$cell == 0)
    trees$cell <- ifelse(
    # (trees$cell == 0) & 
      (vec[(nb-1)*60 + 1] <= trees$x) & (trees$x < vec[(nb-1)*60 + 1]+1) & (200+ligne <= trees$y) & (trees$y < 200+ligne+1), 
    list[nb], trees$cell)
  }

# }
}
```

```{r}
unique(trees$cell)
```

```{r}
trees$cell3 <- rep(0, 30942)
trees$cell3 <- ifelse(
  (vec[1] <= trees$x) & (trees$x < vec[1]+1) & (vec[1] <= trees$y) & (trees$y < vec[1]+1), 
  1, trees$cell3)
```

```{r}
# Inaccurate cell
trees$cell3 <- ifelse(
  (200 <= trees$x) & (trees$x < 300) & (200 <= trees$y) & (trees$y < 300), 
  1, trees$cell3)
```

```{r}
# Invalid
trees$cell3 <- rep(0, 30942)
for (ligne in 1:60){
  
  for(l in 1:60){
    trees$cell3 <- ifelse(
    (vec[l] <= trees$x) & (trees$x < vec[l]+1) & (vec[1] <= trees$y) & (trees$y < vec[1]+1), 
    list[1], trees$cell3)
  }

}
```

```{r}
# When only focusing on 1 10th of the population
plot(x = trees[trees$cell3 == 9,]$x, y = trees[trees$cell3 == 9,]$y, main = "Forest", panel.first=grid())
# Pretty nice (at one point)
```

```{r}
# Test

trees$cell3 <- rep(0, 30942)
nb = 1
ligne = 0

for(c in 1:60){ # En parcourant sur une même ligne
    # if (trees$cell == 0)
    trees$cell <- ifelse(
    (vec[(c-1)*trend + (nb-1) + 1] <= trees$x) & (trees$x < vec[(c-1)*trend + nb]+1) & (200+ligne <= trees$y) & (trees$y < 200+ligne+1) & trees$cell, 
    list[nb], trees$cell)
  }
```

```{r}
# When only focusing on 1 10th of the population
plot(x = trees[trees$cell == 1,]$x, y = trees[trees$cell == 1,]$y, main = "Forest", panel.first=grid())
```

```{r}
# When only focusing on 
plot(x = trees[trees$cell == 9,]$x, y = trees[trees$cell == 9,]$y, main = "Forest", panel.first=grid())
```

```{r}
# When only focusing on 
plot(x = trees[trees$cell == 0,]$x, y = trees[trees$cell == 0,]$y, main = "Forest", panel.first=grid())
```

# Draft for part after 25 June

```{r}
fun_diag <- function(x,y){
  (x + y) <= 1000
}
```

```{r}
random_points$elt <- random_points$rho2/pi
```

```{r}
est_ratio2 <- sum(random_points$elt)
```

```{r}
integral2(fun_diag, 0, 1000, 0, 1000)
```

```{r}
integrate(function(y) {
  sapply(y, function(y){
    integrate(function(x){
      fun_ratio(x,y)}, 0, 1000)
    })
  }, 0, 1000)

```

# Draft for variance in No_cell.Rmd

```{r}
# var_est <- function(f){
#   random_points$carre <- (random_points$rho1)^2
#   est_carre <- sum((random_points$carre)/pi)
# }
```

# Draft for Trees_circle

```{r}
trees_in <- data.frame(useless = rep(0,30942))
col_names <- c()
for (point in 1:n) {
  new_col <- paste("point", point, sep = "")
  a <- random_points[point,]$x
  b <- random_points[point,]$y
  val <- is_point_in_circle(a, b, trees$x, trees$y, 100)*point
  # val <- is_point_in_circle(round(a, digits = 0), round(b, digits = 0), trees$x, trees$y, 100) #*point
  # if (val != 0){
  #  trees$Is_in_circle <- append(trees$Is_in_circle, val[val != 0])
  # }
  trees_in <- trees_in %>% add_column(new_col = val)
  col_names <- append(col_names, new_col)
}
# unique(trees$Is_in_circle)
trees_in[1] <- NULL
colnames(trees_in) <- col_names
```

```{r}
## Draft

nb_trees <- c()

for (placette in 1:n) {
  nb_trees <- append(nb_trees, sum(trees_in[trees_in$point74 != 0,]))
}

sum((nb_trees)/p)
# 28737017 # TOO MUCH, p is (probably) wrong
# 9.028e+09 # if p unchanged i.e. sum(rep((1/1000)*(1/1000), n))
# 57474033 # TOO MUCH, p is (probably) wrong if sum(rep((1/1000)*(1/1000)*((R^2)*pi)/2, n))
```

```{r}
trees$Is_in_circle <- is_point_in_circle(500, 500, trees$x, trees$y, 100)
unique(trees$Is_in_circle)
```

```{r}
# The sample thus obtained
trees[trees$Is_in_circle == TRUE,]
```

```{r}
total_trees <- nrow(trees[trees$Is_in_circle == TRUE,])
```

```{r}
trees$Is_in_circle <- is_point_in_circle(580.869189, 797.312061, trees$x, trees$y, 100)
unique(trees$Is_in_circle)
```


```{r}
# Marginal density: density of the uniform distribution over 1:1000
# Which leads us to the inclusion density function
p <- sum(rep((1/1000)*(1/1000), n)) # :(
# p

# I would say that p changes: area of each circle over total area for each marginal
# p <- sum(rep((1/1000)*(1/1000)*(R^2)*pi, n)) # :(

# p <- sum(rep((1/1000)*(1/1000)*((R^2)*pi)/2, n))
```

## Circle ----------

# Circle2

```{r}
  # list_trees <- c()
  # for (plant in 1:nrow(trees)) {
  #   if (is_point_in_circle(x1, x2, trees[plant, 1], trees[plant, 2], R)){
  #     list_trees <- append(list_trees, plant)
  #   }
    
  # }
```


## Draft for bootstrap ----------

```{r}
# res[(res$ech1$x == res$ech1$x[1]),]
# res[(res$ech2$x == res$ech1$x[1]),]
# Gives the same pair

# res[(res$ech2$x == res$ech2$x[14]),]
# Gives 1 repeated pair twice for the same sample b = 2
```

```{r}
# Try to do bootstrap, success
# test <- data.frame(col = c(1:3))
# res <- f_boot(test, 3)
```

### Complexity ----------

```{r}
# To evaluate complexity
install.packages("cyclocomp")
```

```{r}
library(cyclocomp)
```

```{r}
cyclocomp(circle_nb) # 1
```

```{r}
# Probably less efficient than the version actually used in Bootstrap.Rmd
start.time <- Sys.time()

rho_boot <- tibble(.rows = n)
for (c in 1:B) {
  # assign(ech_, df_boot[c])
  a <- c()
  for (i in 1:n) {
    a <- append(a, circle_nb(df_boot[i, (2*c)-1], df_boot[i, 2*c], R))
  }
  rho_boot <- rho_boot %>% add_column(new_col = a)
  colnames(rho_boot)[c] <- paste("est", c, sep = "")
}

# List of estimated totals thus obtained from each sample
est_boot <- c()
for (c in 1:B) {
  est_boot <- append(est_boot, sum((rho_boot[c])/p))
}

est_boot <- sort(est_boot)

end.time <- Sys.time()
time.taken1 <- end.time - start.time

time.taken1

# Time difference of 52.57304 secs
# Time difference of 52.57391 secs
# Time difference of 54.01066 secs
```

```{r}
### More efficient??? Slower than the above version

start.time <- Sys.time()

rho_boot <- tibble(.rows = n)
for (c in 1:B) {
  # assign(ech_, df_boot[c])
  a <- c()
  for (i in 1:n) {
    if(circle_nb(df_boot[i, (2*c)-1], df_boot[i, 2*c], R) != 0){
    a <- append(a, circle_nb(df_boot[i, (2*c)-1], df_boot[i, 2*c], R))
    }
  }
  a2 <- append(a, rep(0, n-length(a)))
  rho_boot <- rho_boot %>% add_column(new_col = a2)
  colnames(rho_boot)[c] <- paste("est", c, sep = "")
}

# List of estimated totals thus obtained from each sample
est_boot2 <- c()
for (c in 1:B) {
  est_boot2 <- append(est_boot2, sum((rho_boot[c])/p))
}

est_boot2 <- sort(est_boot2)

end.time <- Sys.time()
time.taken2 <- end.time - start.time

time.taken2

# Idea: "a" is sparse: let's simplify by shortening it
# Time difference of 1.526216 mins :(
# Modif: still not good
# Time difference of 1.45528 mins

# That one works (and still too long)
# Time difference of 1.126081 mins
# Time difference of 1.094733 mins
```

```{r}
# For the version actually used in Bootstrap.Rmd
start.time <- Sys.time()

end.time <- Sys.time()
time.taken3 <- end.time - start.time

time.taken3

# Time difference of 54.02127 secs
# Time difference of 50.4839 secs
# Time difference of 53.94593 secs
```

```{r}
est_boot3 <- c()
for (c in 1:B) {
  a <- c()
  for (i in 1:n) {
    a <- append(a, circle_nb(df_boot[i, (2*c)-1], df_boot[i, 2*c], 15))
  }
  est_boot3 <- append(est_boot3, sum(a/p))
}

est_boot3 <- sort(est_boot3)

```

### A first package ----------

```{r}
# Same result with function?
boot.ci(rho_boot, type = "perc")
# Doesn't work (df_boot, est_boot, rho_boot)
```

```{r}
sum((random_points$x/random_points$y)/p)
```

```{r}
rho <- function(df, indice){
  d <- df[indice,] # to enable boot
  return(sum((d$x/d$y)/p))
}
```

```{r}
res_boot <- boot(data=random_points, statistic=circle_nb)
res_boot
# Doesn't work
```

```{r}
boot.ci(res_boot, type = "norm")
```

```{r}
boot.ci(res_boot, type = "basic")
# Warning in norm.inter(t, (1 + c(conf, -conf))/2) :
#  extreme order statistics used as endpoints
```

```{r}
# boot.ci(res_boot, type = "stud") 
# Error in ci.out[[4L]] : subscript out of bounds
```

```{r}
boot.ci(res_boot, type = "perc") 
# Error in ci.out[[4L]] : subscript out of bounds
```

```{r}
boot.ci(res_boot, type = "bca") 
# Error in bca.ci(boot.out, conf, index[1L], L = L, t = t.o, t0 = t0.o,  : 
#  estimated adjustment 'a' is NA
```

### Another package ----------

```{r}
install.packages("bootstrap")
library(bootstrap)
```

```{r}
## The most simple function
f_try <- function(x){
  1
}
```

```{r}
theta <- function(x){mean(x)}
```

```{r}
patch.boot <- bootstrap(x = random_points$x,nboot = 1000,theta = theta, func=NULL)
```

```{r}
sd(patch.boot$thetastar) # bootstrapped standard error
```

```{r}
bcanon(random_points$x, 1000, theta = theta)
```

```{r}
# xdata <- matrix(rnorm(30),ncol=2)
n <- 100
# theta <- function(x,xdata){ cor(xdata[x,1],xdata[x,2]) }
theta <- function(x,xdata){
  a <- c()
  for (i in 1:n) {
    a <- append(a, circle(xdata[i,1], xdata[i,2], R))
    # Change: circle_nb!!!
  }
  est_nb <- sum((a)/p)
}
results <- bcanon(1:n,150,theta,random_points, alpha = 0.95)
```

```{r}
results$confpoints # NaN
```

# Grid for trees ----------

```{r}
# Shift considered to add randomization
trend <- 3
```

```{r}
# (It works a priori)
# l: toutes les lignes ; k: les cellules sur une ligne ; a: abscisse ; b: ordonnée

random_points <- data.frame(x = numeric(), y = numeric())

i <- rank_nb

# list <- list_stable
for (l in 1:(1000/c_dim)) {
  
  for (k in 1:60) { # nombre de fois où on obtient un même identifiant pour une ligne donnée
    colnames(random_points) <- list("x", "y")
    if (length(random_points[(random_points$x > vec[(k + (l-1)*60 -1 + (nb-1)*60)%%1000 + 1])
                             & (random_points$x < vec[(k + (l-1)*60 -1 + (nb-1)*60)%%1000 + 1] + 1)
                             & (random_points$y > 200 + (l-1))
                             & (random_points$y < 200 + l) ]) == 0){ # Eviter les doublons dans chaque cellule
    a <- runif(1, vec[(k + (l-1)*60 -1 + (nb-1)*60)%%1000 + 1], vec[(k + (l-1)*60 -1 + (nb-1)*60)%%1000 + 1] + 1)
    b <- runif(1, 200 + (l-1), 200+l)
    random_points <- rbind(random_points, list(a,b))
    }
    # trees$cell <- ifelse(
    # (vec[] <= trees$x) & (trees$x < vec[k + (nb-1)*60] + 1) & (200 + (l-1) <= trees$y) & (trees$y < 200+l), 
    # list_stable[nb],
    # trees$cell)
  }
  # list <- shift(list, n = trend, type = "cyclic") # shift for each line
}

# 36 000 points are randomly selected if nb = 5
# Which is what we want!

```

```{r}
rm(a,b,k,l) # Useless outside loops
```

```{r}
# ESSAI
random_points <- data.frame(x = numeric(), y = numeric())

i <- rank_nb

for (l in 1:(1000/c_dim)) {
  if ((max(trend*l,c_dim*10) %% min(trend*l,c_dim*10)) < (10-i)*c_dim){
    x_init <- i
  }else{
    x_init <- (10-i)*c_dim
  }
  k <- 1
  while (x_init + 10*c_dim*k < 1000) {
    a <- runif(1, x_init + 10*c_dim*k, x_init + 10*c_dim*k + 1)
    b <- runif(1, (l-1)*c_dim, l*c_dim)
    random_points <- rbind(random_points, list(a,b))
    k <- k+1
  }
}
colnames(random_points) <- list("x", "y")
```

```{r}
plot(x = random_points$x, y = random_points$y, main = "Random points", panel.first=grid())
# , xlim = c(0, 1000), ylim = c(0, 1000))
```

```{r}
plot(x = random_points[(random_points$x < 210),]$x, y = random_points[(random_points$x < 210),]$y, main = "Random points", panel.first=grid(), xlim = c(200, 210), ylim = c(200, 220))
```

```{r}
plot(x = random_points$x, y = random_points$y, main = "Random points", panel.first=grid(), ylim = c(0, 210))
```

```{r}
# ESSAI
random_points <- data.frame(x = numeric(), y = numeric())

# i <- rank_nb

for (l in 0:15) {
  reste <- (max(trend*l*c_dim,c_dim*10) %% min(trend*l*c_dim,c_dim*10))
  # reste <- trend*l*c_dim %% c_dim*10
  cat("reste:",reste,"\n")
  cat("trend*l*c_dim:",trend*l*c_dim,"\n")
  cat("c_dim*10:",c_dim*10,"\n")
  if (l==0){
    x_init <- i*c_dim
    # trend*l*c_dim
    print("In if")
  }else if (reste < (10-i)*c_dim){
    x_init <- reste + i*c_dim
    # trend*l*c_dim
    print("In else if")
  }else{
    x_init <- reste - (10-i)*c_dim
    print("In else")
  }
  cat("x_init:",x_init,"\n")
  k <- 0
  while (x_init + 10*c_dim*k < 1000) {
    # a <- runif(1, x_init + 10*c_dim*k, x_init + 10*c_dim*k + 1)
    # b <- runif(1, l*c_dim, (l+1)*c_dim)
    a <- ((x_init + 10*c_dim*k)+(x_init + 10*c_dim*k + c_dim))/2
    b <- ((l*c_dim)+(l+1)*c_dim)/2
    random_points <- rbind(random_points, list(a,b))
    k <- k+1
  }
}
colnames(random_points) <- list("x", "y")
```

```{r}
plot(x = random_points$x, y = random_points$y, main = "Regular points", panel.first=grid(), xlim = c(0, 1000), ylim = c(0, 160))
```

```{r}
plot(x = random_points$x, y = random_points$y, main = "Regular points", panel.first=grid(), xlim = c(0, 150), ylim = c(0, 100))
```

Problème avec la deuxième ligne, i.e. l=1. 
Le premier point de cette ligne a une coordonnée x trop élevée.

Ex (trend=9, i=9):
reste: 10 
trend*l*c_dim: 90 
c_dim*10: 100 
[1] "In else"
x_init: 0

Ex (trend=3, i=9):
reste: 10 
trend*l*c_dim: 30 
c_dim*10: 100 
[1] "In else"
x_init: 0 

Ex (trend=3, i=5):
reste: 10 
trend*l*c_dim: 30 
c_dim*10: 100 
[1] "In else if"
x_init: 60 

NUL

trend forcément égale à 3 (?)

```{r}
plot(x = random_points$x, y = random_points$y, main = "Regular points", panel.first=grid())
```

# Bootstrap ----------

## ABC-BCA

```{r}
## WARNING:
## Useless function for now!

# Largely based on the code given in https://gitlab.com/scottkosty/bootstrap/-/blob/master/R/bcanon.R
# Function explained in Efron and Tibshirani (1993)
bcanon <- function(x,bootsam,theta,...,alpha =
                     c(.025,.05,.1,.16,.84,.9,.95,.975)) { 
    if (!all(alpha < 1) || !all(alpha > 0))
      stop("All elements of alpha must be in (0,1)")

    # alpha_sorted <- sort(alpha)
    # if (nboot <= 1/min(alpha_sorted[1],1-alpha_sorted[length(alpha_sorted)]))
    #   warning("nboot is not large enough to estimate your chosen alpha.")

    call <- match.call()
    # n <- length(x)
    n <- nrow(x)
    # thetahat <- theta(x,...)
    a <- c()
    for (i in 1:n) {
      a <- append(a, theta(x[i, 1], x[i, 2]))
    }
    # Estimated total thus obtained from the initial sample
    thetahat <- sum(a/p)
    
    nboot <- length(bootsam)/2
    # bootsam<- matrix(sample(x,size=n*nboot,replace=TRUE),nrow=nboot)

    # thetastar <- apply(bootsam,1,theta,...)
    thetastar <- c()
    for (c in 1:B) {
      a <- c()
      for (i in 1:n) {
        a <- append(a, theta(bootsam[i, (2*c)-1], bootsam[i, 2*c]))
      }
      thetastar <- append(thetastar, sum(a/p))
    }
    thetastar <- sort(thetastar)

    z0 <- qnorm(sum(thetastar<thetahat)/nboot)
    
    u <- rep(0,n)
    for(i in 1:n){
        # u[i] <- theta(x[-i],...)
        x_i <- x[-i]
        a <- c()
        for (j in 1:n) {
          a <- append(a, theta(x_i[j, 1], x_i[j, 2]))
        }
        # Estimated total thus obtained from the initial sample
        u[i] <- sum(a/p)
    }
    uu <- mean(u)-u
    acc <- sum(uu*uu*uu)/(6*(sum(uu*uu))^1.5)
    
    zalpha <- qnorm(alpha)
    
    tt <- pnorm(z0+ (z0+zalpha)/(1-acc*(z0+zalpha)))
    
    confpoints <- quantile(x=thetastar,probs=tt,type=1)
    names(confpoints) <- NULL
    confpoints <- cbind(alpha,confpoints)
    dimnames(confpoints)[[2]] <- c("alpha","bca point")
    return(list(confpoints=confpoints, 
                z0=z0, 
                acc=acc, 
                u=u, 
                call=call))
}
```

```{r}
# bcanon(random_points,df_boot,circle_nb,alpha = .95)
# Produces an error
```

# Alarm / beep / message when it finishes running ----------

```{r}
#Have R email you when it's done running.
###Calculating - your wish is R's command.
library(mail)
#Send yourself an email - specify your preferred email address, subject, and message. The password is fixed at "rmail".
sendmail("xxxxx@xxxxx.com", subject="Notification from R", message="Conditions finished running!", password="rmail")

alarm()

install.packages("audio")
library(audio)
install.packages("beepr")
library(beepr)
beep()
```

# Variance ----------

```{r}
# Unbiased variance

# Test
test <- c(1,2,3,5)
var(test) # 2.916667

varbis <- function(x){
  
}
```

# Print LaTeX code as output of R code (failure) ----------

```{r}
print("* $H_o = `r 1 + 1`$")
b0 = "$\\beta_0$"
m3 = "$m^3$"
cat("thing:",m3)
cat("thing:",`b0`)
```

```{r}
print(bquote(m^2))
```

# Small examples for MC_all.Rmd ----------

```{r}
# Small test

start.time <- Sys.time()

res_MC <- MonteCarlo(100, 200)

end.time <- Sys.time()
time.taken <- end.time - start.time

time.taken
```

```{r}
# mean(as.vector(t(res_MC$Estimators[1,])))

cat("95% confidence interval using the percentile method: 
      [", res_MC$`Confidence Intervals`$Percentile[1,1], ";", res_MC$`Confidence Intervals`$Percentile[2,1], "]\n" )

# cat("95% confidence interval using the reverse percentile method: 
#       [", est_init*2 - lim_sup, ";", est_init*2 - lim_inf, "]\n" )
```

```{r}
# Small test

start.time <- Sys.time()

res_MC_boot <- MC_boot(100, 200, 100)

end.time <- Sys.time()
time.taken <- end.time - start.time

time.taken
```

# Old f_boot with the tibble point of view still readable for MC_all.Rmd ----------

```{r}
f_boot <- function(df_sample, B){
  # df_sample: original sample; 
  # B: number of bootstrap samples made thanks to df_sample
  
  # df_boot <- tibble(.rows = (nrow(df_sample)-1))
  df_boot <- data.frame(useless = rep(0, nrow(df_sample)-1))
  for (b in 1:B) {
    nb <- sample(1:nrow(df_sample), (nrow(df_sample)-1), replace = TRUE)
    # (n-1) points at random
    sample_b <- df_sample[nb,]
    # df_boot <- df_boot %>% add_column(new_col = sample_b)
    df_boot <- cbind(df_boot, sample_b)
    colnames(df_boot)[((b-1)*4+1 + 1):(b*4+1)] <- c(paste("ech", b, colnames(df_sample)[1], sep = ""), paste("ech", b, colnames(df_sample)[2], sep = ""), paste("ech", b, colnames(df_sample)[3], sep = ""), paste("ech", b, colnames(df_sample)[4], sep = ""))
  }
  df_boot$useless <- NULL
  # return(do.call(data.frame, df_boot))
  return(df_boot)
  # Return a data frame with B samples of as many variables as we want (in this application, 4) and of size (n-1)
}
```

VAR_vol <- c()
for (elt in res2$Variances) {
  VAR_vol <- append(VAR_vol, elt$var_vol)
}

VAR_ratio <- c()
for (elt in res2$Variances) {
  VAR_ratio <- append(VAR_ratio, elt$var_ratio)
}

## Non-optimal version of coverage rates in MC_all.Rmd ----------

```{r}
## We want all the CI based on Normal distribution obtained for each parameter of interest, 
# to find the coverage rate
CI_nb <- data.frame(useless = c(0,0))
CI_vol <- data.frame(useless = c(0,0))
CI_ratio <- data.frame(useless = c(0,0))
for (elt in res2$`Confidence Intervals`) {
  CI_nb <- cbind(CI_nb, elt$Normal$lim_nb)
  CI_vol <- cbind(CI_vol, elt$Normal$lim_vol)
  CI_ratio <- cbind(CI_ratio, elt$Normal$lim_ratio)
}
CI_nb$useless <- NULL
CI_vol$useless <- NULL
CI_ratio$useless <- NULL

CI_nb <- as.data.frame(t(CI_nb))
rownames(CI_nb) <- 1:(nrow(CI_nb))
colnames(CI_nb) <- c("x", "y")

CI_vol <- as.data.frame(t(CI_vol))
rownames(CI_vol) <- 1:(nrow(CI_vol))
colnames(CI_vol) <- c("x", "y")

CI_ratio <- as.data.frame(t(CI_ratio))
rownames(CI_ratio) <- 1:(nrow(CI_ratio))
colnames(CI_ratio) <- c("x", "y")
```

```{r}
# Check the coverage rate
TC_nb <- (1/nrow(CI_nb))*sum( mapply(function(a,b){as.numeric((29272 > a) & (29272 < b))}, CI_nb$x, CI_nb$y) )
TC_vol <- (1/nrow(CI_vol))*sum( mapply(function(a,b){as.numeric((5412.722 > a) & (5412.722 < b))}, CI_vol$x, CI_vol$y) )
TC_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a,b){as.numeric((0.1849112 > a) & (0.1849112 < b))}, CI_ratio$x, CI_ratio$y) )
cat("Concerning the normal approach, the coverage rate are the following: \n - for the number of trees: ", TC_nb, "\n - for the volume of trees: ", TC_vol, "\n - for the ratio volume / number of trees: ", TC_ratio)
```



```{r}
## We want all the Percentile CI obtained for each parameter of interest, 
# to find the coverage rate
CI_perc_nb <- data.frame(useless = c(0,0))
CI_perc_vol <- data.frame(useless = c(0,0))
CI_perc_ratio <- data.frame(useless = c(0,0))
for (elt in res2$`Confidence Intervals`) {
  CI_perc_nb <- cbind(CI_perc_nb, elt$Percentile$lim_nb)
  CI_perc_vol <- cbind(CI_perc_vol, elt$Percentile$lim_vol)
  CI_perc_ratio <- cbind(CI_perc_ratio, elt$Percentile$lim_ratio)
}
CI_perc_nb$useless <- NULL
CI_perc_vol$useless <- NULL
CI_perc_ratio$useless <- NULL

CI_perc_nb <- as.data.frame(t(CI_perc_nb))
rownames(CI_perc_nb) <- 1:(nrow(CI_perc_nb))
colnames(CI_perc_nb) <- c("x", "y")

CI_perc_vol <- as.data.frame(t(CI_perc_vol))
rownames(CI_perc_vol) <- 1:(nrow(CI_perc_vol))
colnames(CI_perc_vol) <- c("x", "y")

CI_perc_ratio <- as.data.frame(t(CI_perc_ratio))
rownames(CI_perc_ratio) <- 1:(nrow(CI_perc_ratio))
colnames(CI_perc_ratio) <- c("x", "y")
```

```{r}
# Check the coverage rate
TC_nb <- (1/nrow(CI_perc_nb))*sum( mapply(function(a,b){as.numeric((29272 > a) & (29272 < b))}, CI_perc_nb$x, CI_perc_nb$y) )
TC_vol <- (1/nrow(CI_perc_vol))*sum( mapply(function(a,b){as.numeric((5412.722 > a) & (5412.722 < b))}, CI_perc_vol$x, CI_perc_vol$y) )
TC_ratio <- (1/nrow(CI_perc_ratio))*sum( mapply(function(a,b){as.numeric((0.1849112 > a) & (0.1849112 < b))}, CI_perc_ratio$x, CI_perc_ratio$y) )
cat("Concerning the percentile approach, the coverage rate are the following: \n - for the number of trees: ", TC_nb, "\n - for the volume of trees: ", TC_vol, "\n - for the ratio volume / number of trees: ", TC_ratio)
```

```{r}
## We want all the Reverse Percentile CI obtained for each parameter of interest, 
# to find the coverage rate
CI_nb <- data.frame(useless = c(0,0))
CI_vol <- data.frame(useless = c(0,0))
CI_ratio <- data.frame(useless = c(0,0))
for (elt in res2$`Confidence Intervals`) {
  CI_nb <- cbind(CI_nb, elt$`Reverse percentile`$lim_nb)
  CI_vol <- cbind(CI_vol, elt$`Reverse percentile`$lim_vol)
  CI_ratio <- cbind(CI_ratio, elt$`Reverse percentile`$lim_ratio)
}
CI_nb$useless <- NULL
CI_vol$useless <- NULL
CI_ratio$useless <- NULL

CI_nb <- as.data.frame(t(CI_nb))
rownames(CI_nb) <- 1:(nrow(CI_nb))
colnames(CI_nb) <- c("x", "y")

CI_vol <- as.data.frame(t(CI_vol))
rownames(CI_vol) <- 1:(nrow(CI_vol))
colnames(CI_vol) <- c("x", "y")

CI_ratio <- as.data.frame(t(CI_ratio))
rownames(CI_ratio) <- 1:(nrow(CI_ratio))
colnames(CI_ratio) <- c("x", "y")
```

```{r}
# Check the coverage rate
TC_nb <- (1/nrow(CI_nb))*sum( mapply(function(a,b){as.numeric((29272 > a) & (29272 < b))}, CI_nb$x, CI_nb$y) )
TC_vol <- (1/nrow(CI_vol))*sum( mapply(function(a,b){as.numeric((5412.722 > a) & (5412.722 < b))}, CI_vol$x, CI_vol$y) )
TC_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a,b){as.numeric((0.1849112 > a) & (0.1849112 < b))}, CI_ratio$x, CI_ratio$y) )
cat("Concerning the reverse percentile approach, the coverage rate are the following: \n - for the number of trees: ", TC_nb, "\n - for the volume of trees: ", TC_vol, "\n - for the ratio volume / number of trees: ", TC_ratio)
```



# Old version of tes_boot_short_2.Rmd (strata different from lines)


```{r}
f_boot <- function(df_sample, B){
  # df_sample: original sample; 
  # B: number of bootstrap samples made thanks to df_sample
  
  df_boot <- data.frame(useless = rep(0, nrow(df_sample)-100))
  for (b in 1:B) {
    # nb <- sample(unique(df_sample[,3]), (length(unique(df_sample[,3]))-1), replace = TRUE)
    # (H-1) strata at random
    sample_b <- data.frame(x = numeric(), y = numeric(), z = numeric(), t = numeric(), w = numeric())
    for (number in unique(df_sample[,3])){
      truc <- sample(rownames(df_sample[df_sample[,3] == number,]), (nrow(df_sample[df_sample[,3] == number,])-1), replace = TRUE)
      muche <- mapply(function(RRRRR){df_sample[rownames(df_sample) == RRRRR,]}, truc)
      sample_b <- rbind(sample_b, t(muche))
      # sample_b <- rbind(sample_b, df_sample[df_sample[,3] == number,])
    }
    df_boot <- cbind(df_boot, sample_b)
    colnames(df_boot)[((b-1)*5+1 + 1):(b*5+1)] <- c(paste("ech", b, colnames(df_sample)[1], sep = ""), paste("ech", b, colnames(df_sample)[2], sep = ""), paste("ech", b, colnames(df_sample)[3], sep = ""), paste("ech", b, colnames(df_sample)[4], sep = ""), paste("ech", b, colnames(df_sample)[5], sep = ""))
  }
  df_boot$useless <- NULL
  return(df_boot)
  # Return a data frame with B samples of as many variables as we want (in this application, 5)
}
```

```{r}
# Making of estimations for each sample made by the bootstrap method
est_boot <- function(df, p){
  # df: dataframe with 5*B columns and n rows
  
  n <- nrow(df) + 1 # sample size of the initial sample
  nboot <- length(df)/5 # number of bootstrap samples
  vec_est1 <- c()
  vec_est2 <- c()
  vec_est3 <- c()
  for (c in 1:nboot) {
    vec_est1 <- append(vec_est1, (900/9)*sum(unlist(df[,4 + (5*(c-1))])/p))
    vec_est2 <- append(vec_est2, (900/9)*sum(unlist(df[,5*c])/p))
    vec_est3 <- append(vec_est3, ((900/9)*sum(unlist(df[,5*c])/p))/((900/9)*sum(unlist(df[,4 + (5*(c-1))])/p)))
    # (n_h/(n_h-1))*(n/n_h) is the correction needed since we choose only (n_h-1) points per strata
  }
  vec_est <- data.frame(est_nb = vec_est1, est_vol = vec_est2, est_ratio = vec_est3)
  return(vec_est)
  # Data frame with 3 estimations for each sample
}
```

```{r}
### Function to automate Monte Carlo + bootstrap method

MC_boot <- function(n, B1, B2){
  # B1: number of iterations for MC;
  # B2: number of iterations for bootstrap
  
  p <- sum(rep((1/1000)*(1/1000), n))
  BOOT_df <- list() # All local variables
  BOOT_est <- list() # All estimations
  BOOT_var <- list() # Variances
  BOOT_CI <- list() # Confidence Intervals
  for (b in 1:B1) { # One MC iteration at a time
    # Uniform sampling over the whole territory
    df_grid <- sampling_grid(i,c_dim)
    a1 <- df_grid$x
    a2 <- df_grid$y
    a3 <- df_grid$Stratum
    var <- mapply(circle_all, a1, a2)
    df_b <- data.frame(x = a1, y = a2, w = a3, z = t(var)[,1], t = t(var)[,2])
    colnames(df_b) <- c(paste("x.MC", b, sep = ""), paste("y.MC", b, sep = ""), paste("h.MC", b, sep = ""), paste("nb.MC", b, sep = ""), paste("vol.MC", b, sep = ""))
    est_b <- t(data.frame(x = sum(df_b[4] /p), y = sum(df_b[5] /p), z = (sum(df_b[5] /p))/(sum(df_b[4]/p))))
    
    # Bootstrap iterations
    df_boot <- f_boot(df_b, B2)
    est_boot_val <- est_boot(df_boot, p)
    
    BOOT_var[[b]] <- list(var_nb = var(est_boot_val$est_nb), var_vol = var(est_boot_val$est_vol), var_ratio = var(est_boot_val$est_ratio))
    names(BOOT_var)[b] <- paste("Variance", b, sep = "")
    BOOT_df <- c(BOOT_df, list(data_init = df_b, data_boot = df_boot))
    names(BOOT_df)[(2*b-1):(2*b)] <- c(paste("df_MC", b, sep = ""), paste("df_boot", b, sep = ""))
    BOOT_est <- c(BOOT_est, list(est_init_b = est_b, est_boot_b = est_boot_val))
    names(BOOT_est)[(2*b-1):(2*b)] <- c(paste("est_MC", b, sep = ""), paste("est_boot", b, sep = ""))
    
    # Confidence intervals
    norm_CI <- data.frame(useless = rep(0, 2))
    perc_CI <- data.frame(useless = rep(0, 2))
    rev_perc_CI <- data.frame(useless = rep(0, 2))
    for (l in 1:3) { # Loop: one estimator each time
      sorted_est <- sort(est_boot_val[,l])
      lim_inf <- sorted_est[floor(B2*2.5/100)]
      lim_sup <- sorted_est[B2 - floor(B2*2.5/100)]
      perc_CI <- cbind(perc_CI, data.frame(c(lim_inf, lim_sup)))
      rev_perc_CI <- cbind(rev_perc_CI, data.frame(c(est_b[l,]*2 - lim_sup, est_b[l,]*2 - lim_inf)))
      norm_CI <- cbind(norm_CI, data.frame(c(est_b[l,]-qnorm(0.975)*sqrt(var(est_boot_val[,l])), est_b[l,]+qnorm(0.975)*sqrt(var(est_boot_val[,l])))))
    }
    norm_CI$useless <- NULL
    perc_CI$useless <- NULL
    rev_perc_CI$useless <- NULL
    colnames(norm_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    colnames(perc_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    colnames(rev_perc_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    all_CI <- list(Normal = norm_CI, Percentile = perc_CI, `Reverse percentile` = rev_perc_CI)
    # BOOT_CI <- c(BOOT_CI, CI_b = all_CI)
    BOOT_CI[[b]] <- all_CI
    names(BOOT_CI)[b] <- paste("CI", b, sep = "")
  }
  return(list(`Local Variables` = BOOT_df, Estimations = BOOT_est, Variances = BOOT_var, `Confidence Intervals` = BOOT_CI))
  # Local Variables: local variables (number and volume) for each point in each sample
  # Estimations: 3 estimations (number, volume, ratio volume / number) for each sample
  # Variances: mean of the bootstrap variance for each estimator
  # Confidence Intervals: 3 different forms of 95% confidence intervals, for each total / ratio
}
```

```{r}
start.time <- Sys.time()

res2 <- MC_boot(n, B1 = 10, B2 = 4)
# Just one circle to begin with

end.time <- Sys.time()
time.taken <- end.time - start.time

time.taken
```

## Plots ----------

```{r}
install.packages("ggplot2")
library(ggplot2)

# Setup the data
m <- matrix(c(8,3,4,1,5,9,6,7,2), nrow=3, ncol=3)
df <- expand.grid(x=1:ncol(m),y=1:nrow(m))
df$val <- m[as.matrix(df[c('y','x')])]

library(ggplot2)
library(scales)
test <- ggplot(df, aes(x=x, y=y, label=val)) + 
  geom_tile(fill='transparent', colour = 'black') + 
  geom_text(size = 14) + 
  scale_y_reverse() +
  theme_classic() + 
  theme(axis.text  = element_blank(),
        panel.grid = element_blank(),
        axis.line  = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

plot(test)
```

```{r}
# Create a data frame with the coordinates and colors
grid_data <- expand.grid(x = 1:10, y = 1:10)  # 10x10 grid
grid_data$color <- "white"  # Default color for all squares

# Specify the squares to be colored
colored_squares <- data.frame(
  x = c(2, 4, 6, 8),
  y = c(3, 5, 7, 9),
  color = c("red", "blue", "green", "yellow")
)

# Merge the colored squares into the grid data
grid_data <- merge(grid_data, colored_squares, by = c("x", "y"), all.x = TRUE)
grid_data$color.y[is.na(grid_data$color.y)] <- "white" # Set NA colors to white
# c(rep("white", 100))

ggplot(grid_data, aes(x = x, y = y, fill = color.y)) +
  geom_tile(colour = "black") +  # Draw the squares with black borders # 
  scale_fill_identity() +  # Use the colors specified in the data
  theme_minimal() +  # Minimal theme for better visualization
  theme(
    axis.title = element_blank(),  # Remove axis titles
    axis.text = element_blank(),   # Remove axis text
    axis.ticks = element_blank(),  # Remove axis ticks
    panel.grid = element_blank()   # Remove grid lines
  ) +
  coord_fixed()  # Ensure squares are not stretched
```

##### From All_param -----------

```{r eval=FALSE, include=FALSE}
### DRAFT

  # Coverage rate
  TC_nb <- (1/nrow(CI_nb))*sum( mapply(function(a,b){as.numeric((29272 > a) & (29272 < b))}, CI_nb[1], CI_nb[2]) )
  TC_vol <- (1/nrow(CI_vol))*sum( mapply(function(a,b){as.numeric((5412.722 > a) & (5412.722 < b))}, CI_vol[1], CI_vol[2]) )
  TC_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a,b){as.numeric((0.1849112 > a) & (0.1849112 < b))}, CI_ratio[1], CI_ratio[2]) )
  
  # Lower tail
  low_tail_nb <- (1/nrow(CI_nb))*sum( mapply(function(a){as.numeric(29272 < a)}, CI_nb[1]) )
  low_tail_vol <- (1/nrow(CI_vol))*sum( mapply(function(a){as.numeric(5412.722 < a)}, CI_vol[1]) )
  low_tail_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a){as.numeric(0.1849112 < a)}, CI_ratio[1]) )
  
  # Upper tail
  up_tail_nb <- (1/nrow(CI_nb))*sum( mapply(function(b){as.numeric(29272 > b)}, CI_nb[2]) )
  up_tail_vol <- (1/nrow(CI_vol))*sum( mapply(function(b){as.numeric(5412.722 > b)}, CI_vol[2]) )
  up_tail_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(b){as.numeric(0.1849112 > b)}, CI_ratio[2]) )
  
  # Mean length of CIs
  length_nb <- mean( mapply(function(a,b){b-a}, CI_nb[1], CI_nb[2]) )
  length_vol <- mean( mapply(function(a,b){b-a}, CI_vol[1], CI_vol[2]) )
  length_ratio <- mean( mapply(function(a,b){b-a}, CI_ratio[1], CI_ratio[2]) )
  
  df_TC <- data.frame(TC = c(TC_nb, TC_vol, TC_ratio), Upper = c(low_tail_nb, low_tail_vol, low_tail_ratio), Lower = c(up_tail_nb, up_tail_vol, up_tail_ratio), Mean_length = c(length_nb, length_vol, length_ratio))
```

### LaTeX tables from R data frames ----------

```{r}
library(xtable)
```

```{r}
# Tables
print(xtable(TC_normal, caption = "Test"))
```

```{r}
truc <- TC_normal %>%
  kable("latex", booktabs = TRUE)
truc
```

```{r}
TC_normal %>%
  kable("latex", booktabs = TRUE) %>%
  kable_styling(latex_options = "hold_position") %>%
  row_spec(0, bold = TRUE) %>%
  collapse_rows(columns = 1, latex_hline = "major")
```

### Simplification of All_tables ------------

```{r}
test2 <- paste("True integrals are the following:\n\nNumber of trees:", nrow(trees), "\nTotal volume:", sum(trees$v), 
    "\nWhich leads to the following ratio \"Total volume / Number of trees\":", sum(trees$v)/nrow(trees),
    "\n\nNumber of small trees:", nrow(trees[(pi*trees$d130 < 70.5),]), "\nVolume of small trees:", sum(trees[(pi*trees$d130 < 70.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 < 70.5),]$v)/nrow(trees[(pi*trees$d130 < 70.5),]),
    "\n\nNumber of medium trees:", nrow(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]), "\nVolume of medium trees:", sum(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]$v)/nrow(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]),
    "\n\nNumber of big trees:", nrow(trees[(pi*trees$d130 > 117.5),]), "\nVolume of big trees:", sum(trees[(pi*trees$d130 > 117.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 > 117.5),]$v)/nrow(trees[(pi*trees$d130 > 117.5),])
    )
```

```{r}
cat("Mean of the variance of bootstrap samples:\n - for the number of trees:", VAR_df[1], "\n - for the volume of trees:", VAR_df[5], "\n - for the ratio volume / number of trees:", mean(unlist(VAR_ratio)),
        "\n\n - for the number of small trees:", VAR_df[2], "\n - for the volume of small trees:", VAR_df[6], "\n - for the ratio volume / number of trees:", mean(unlist(VAR_ratio_s)),
    "\n\n - for the number of medium trees:", VAR_df[3], "\n - for the volume of medium trees:", mean(unlist(VAR_vol_m)), "\n - for the ratio volume / number of trees:", mean(unlist(VAR_ratio_m)),
    "\n\n - for the number of big trees:", VAR_df[4], "\n - for the volume of big trees:", mean(unlist(VAR_vol_b)), "\n - for the ratio volume / number of trees:", mean(unlist(VAR_ratio_b)))

# Example:
```

```{r}
# For z0 in nonparametric BCa
# Same as: mapply(function(one, long){qnorm(sum(long<one)/nboot)}, t(est_init),est_boot_val)
```

```{r}
# Really useless
from_local <- function(j){sum(df_b[2+j] /p)} # (nb_var+2)*(b-1)
```



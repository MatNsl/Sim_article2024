---
title: "Bootstrap"
output: pdf_document
date: "2024-06-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("boot") # for bootstrap
```

```{r}
library(readxl) # to read the initial file
library(magrittr) # for pipes
library(tibble) # for add_column
library(boot)
```

Notes from Efron and Tibshirani (1993):
"It is important to note that B = 100 or 200 is not adequate for confidence interval construction, see Chapter 19." (p161)

# Preliminaries

((We do not need the artificial forest for now. We just need a virtual 1000x1000 square.))

```{r}
# Importing the database with the artificial forest
trees <- read_excel("~/work/Sim_article2024/Data/artificial_forest_round.xls")
```

```{r}
### Constant values

# Sample size
n <- 100

# Marginal density: density of the uniform distribution over 1:1000
# Which leads us to the inclusion density function
p <- sum(rep((1/1000)*(1/1000), n))

# Number of bootstrap samples
B <- 500

# Radius to consider for the circle around each sampled point
R <- 5
```

# Creating one sample

```{r}
# Dataframe containing all coordinates of n randomly chosen points
# Uniform sampling over the whole territory
random_points <- data.frame(x = runif(n, 0, 1000), y = runif(n, 0, 1000))
```

# Creating other samples based on the previous one

```{r}
f_boot <- function(df_sample, B){
  # df_sample: original sample; B: number of bootstrap samples made thanks to df_sample
  
  df_boot <- tibble(.rows = nrow(df_sample))
  for (b in 1:B) {
    nb <- sample(1:nrow(df_sample), nrow(df_sample), replace = TRUE)
    sample_b <- df_sample[nb,]
    df_boot <- df_boot %>% add_column(new_col = sample_b)
    colnames(df_boot)[b] <- paste("ech", b, sep = "")
  }
  return(do.call(data.frame, df_boot))
  # Return a data frame with B samples of 2 variables and of size n
}
```

```{r}
# Making of bootstrap samples
df_boot <- f_boot(random_points, B)
```

```{r}
# Function to produce a local variable
source("~/work/Sim_article2024/Useful_functions/Circle.R")
```

```{r}
rho_boot <- tibble(.rows = n)
for (c in 1:B) {
  # assign(ech_, df_boot[c])
  a <- c()
  for (i in 1:n) {
    a <- append(a, circle_nb(df_boot[i, (2*c)-1], df_boot[i, 2*c], R))
  }
  rho_boot <- rho_boot %>% add_column(new_col = a)
  colnames(rho_boot)[c] <- paste("est", c, sep = "")
}

# List of estimated totals thus obtained from each sample
est_boot <- c()
for (c in 1:B) {
  est_boot <- append(est_boot, sum((rho_boot[c])/p))
}

est_boot <- sort(est_boot)
```

```{r}
rm(a, c, i, col_names, col_)
```

```{r}
# Confidence Interval based on the percentile approach
lim_inf <- est_boot[floor(B*2.5/100)]
lim_sup <- est_boot[B - floor(B*2.5/100)]
cat("Un intervalle de confiance à 95% par la méthode des percentiles est : [", lim_inf, ";", lim_sup, "]" )
```

```{r}
rho_init <- tibble(.rows = n)
# col_names <- c()
# for (c in 1:B) {
#   col_ <- paste("est", c, sep = "")
  # ech_ <- paste("ech", c, sep = "")
  # assign(ech_, df_boot[c])
  a <- c()
  for (i in 1:n) {
    # loc_var <- 
    a <- append(a, circle_nb(random_points[i, 1], random_points[i, 2], R))
    }
  # a <- circle(df_boot[(2*c)-1], df_boot[2*c], R)
  # print(col_)
  rho_init <- rho_init %>% add_column("ech_init" = a) # 
  # col_names <- append(col_names, col_)
  # colnames(rho_boot) <- col_names
# }

# colnames(rho_boot) <- "ech_init"

# 3rd step: List of estimated totals thus obtained from each sample
est_init <- c()

est_tot <- sum((rho_init[1])/p)
est_init <- append(est_init, est_tot)

est_init <- sort(est_init)
```

```{r}
# Confidence Interval based on the reverse percentile approach
cat("Un intervalle de confiance à 95% par la méthode des reverse percentiles est : [", est_init*2 - lim_sup, ";", est_init*2 - lim_inf, "]" )
```

```{r}
# Same result with function?
boot.ci(rho_boot, type = "perc")
# Doesn't work (df_boot, est_boot, rho_boot)
```




```{r}
sum((random_points$x/random_points$y)/p)
```

```{r}
rho <- function(df, indice){
  d <- df[indice,] # to enable boot
  return(sum((d$x/d$y)/p))
}
```

```{r}
res_boot <- boot(data=random_points, statistic=circle_nb)
res_boot
# Doesn't work
```

```{r}
boot.ci(res_boot, type = "norm")
```

```{r}
boot.ci(res_boot, type = "basic")
# Warning in norm.inter(t, (1 + c(conf, -conf))/2) :
#  extreme order statistics used as endpoints
```

```{r}
# boot.ci(res_boot, type = "stud") 
# Error in ci.out[[4L]] : subscript out of bounds
```

```{r}
boot.ci(res_boot, type = "perc") 
# Error in ci.out[[4L]] : subscript out of bounds
```

```{r}
boot.ci(res_boot, type = "bca") 
# Error in bca.ci(boot.out, conf, index[1L], L = L, t = t.o, t0 = t0.o,  : 
#  estimated adjustment 'a' is NA
```

# Another package

```{r}
install.packages("bootstrap")
library(bootstrap)
```

```{r}
## The most simple function
f_try <- function(x){
  1
}
```

```{r}
theta <- function(x){mean(x)}
```

```{r}
patch.boot <- bootstrap(x = random_points$x,nboot = 1000,theta = theta, func=NULL)
```

```{r}
sd(patch.boot$thetastar) # bootstrapped standard error
```

```{r}
bcanon(random_points$x, 1000, theta = theta)
```

```{r}
# xdata <- matrix(rnorm(30),ncol=2)
n <- 100
# theta <- function(x,xdata){ cor(xdata[x,1],xdata[x,2]) }
theta <- function(x,xdata){
  a <- c()
  for (i in 1:n) {
    a <- append(a, circle(xdata[i,1], xdata[i,2], R))
    # Change: circle_nb!!!
  }
  est_nb <- sum((a)/p)
}
results <- bcanon(1:n,150,theta,random_points, alpha = 0.95)
```

```{r}
results$confpoints # NaN
```

```{r}

```

```{r}

```

```{r}

```


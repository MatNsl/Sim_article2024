---
title: "Uniform sampling across the whole territory without any cells"
output: pdf_document
date: "2024-06-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readxl) # to read the initial file
library(data.table) # for shift
library(magrittr) # for pipes
library(tibble) # for add_column
```

# Preliminaries

We do not need the artificial forest for now. We just need a virtual 1000x1000 square.

```{r}
# Sample size
n <- 100
```

```{r}
# Marginal density: density of the uniform distribution over 1:1000
# Which leads us to the inclusion density function
p <- sum(rep((1/1000)*(1/1000), n))
p
```

# Estimates with simple functions and one sample

## Creating one sample

```{r}
# Dataframe containing all coordinates of n randomly chosen points
random_points <- data.frame(x = rep(0, n), y = rep(0, n))
```

```{r}
# Uniform sampling over the whole territory
random_points$x <- runif(n, 0, 1000)
random_points$y <- runif(n, 0, 1000)
```

## First function: (x,y) $\mapsto$ 1

```{r}
## The most simple function
fun1 <- function(x,y){
  1
}
```

```{r}
# 1 given to each sampled point
random_points$rho1 <- rep(1, n)
# Formula given in Cordy (1993), page 3
```

```{r}
# Value to estimate: the area of the territory
area <- 1000*1000
```

```{r}
# Estimated value
est_area <- sum((random_points$rho1)/p) 
# Equal to 1e+06 whatever the chosen points
```

## Second function: (x,y) $\mapsto$ as.numeric(x>y)

```{r}
## Indicator of (x>y)
f_ind <- function(x,y){
  as.numeric(x > y)
}
```

```{r}
# Value to estimate
half_area <- 1000*1000/2
```

```{r}
# 1 given to each sampled point that satisfies x>y
random_points$rho2 <- f_ind(random_points$x,random_points$y)
```

```{r}
# Estimated value
est_ind <- sum((random_points$rho2)/p)
est_ind
# 510000 e.g.
```

## Third function: (x,y) $\mapsto$ x

```{r}
# x given to each point
f_x <- function(x,y){
  x
}
```

```{r}
# Value to estimate
val_x <- 500000000
```

```{r}
# Estimated value
est_x <- sum((random_points$x)/p) # = 
est_x
# 499690876 e.g.
```

# Variances with simple functions and one sample

Variance formula for the uniform case is based on the formula given by Cordy (1993), theorem 2 page 5 combined with the inclusion density given for example 1 page 4, which gives a simplified formula for this particular case.

## Case of the area

```{r}
# New variable: rho1^2
random_points$carre <- (random_points$rho1)^2
est_carre <- sum((random_points$carre)/p)
# est_carre = est_area # Logical since rho1 = carre = 1
```

```{r}
var_area <- est_carre/p - (1/n)*(est_area^2)
var_area
# The empirical variance is null as expected
```

```{r}
# fun1(x,y)^2 = fun1(x,y)
varTH_area <- area/p - (1/n)*(area^2)
varTH_area
# The theoretical variance is null as expected
# Since the total is equal to the area
```

## Case of half of the area

```{r}
var_ind <- est_ind/p - (1/n)*(est_ind^2)
var_ind
# Empirical variance: 2.491e+09 (huge)
```

```{r}
# f_ind(x,y)^2 = f_ind(x,y)
varTH_ind <- half_area/p - (1/n)*(half_area^2)
varTH_ind
# Theoretical variance: 2.5e+09, i.e. around 2.498e+09
# Close to the empirical one: great
```

## Case of the function that keeps x

```{r}
f_x2 <- function(x,y){
  x^2
}
```

```{r}
# Estimated value
est_x2 <- sum(((random_points$x)^2)/p)
est_x2
# 499690876 e.g.
```

```{r}
var_x <- est_x2/p - (1/n)*(est_x^2)
var_x
# Empirical variance: 8.407871e+14 ?!
```

```{r}
# f_ind(x,y)^2 = f_ind(x,y)
# varTH_x <- integral2(f_x, 0, 1000, 0, 1000)$Q/p - (1/n)*(integral2(f_x, 0, 1000, 0, 1000)$Q^2)
# varTH_x
# Theoretical variance: 2498391345, i.e. around 2.498e+09
# Close to the empirical one: great
```

# Monte Carlo

## First MC application step by step with the function that keeps x

```{r}
# Number of replications for the Monte-Carlo method
B <- 1000
```

```{r}
# Initialization with a first sample
series_MC <- data.frame(x.1 = runif(n, 0, 1000), y.1 = runif(n, 0, 1000))
col_names <- c("x1", "y1")
```

```{r}
# Making as many samples as necessary for MC (i.e. B)
for (b in 2:B) {
  x <- paste("x", b, sep = "")
  y <- paste("y", b, sep = "")
  # Uniform sampling over the whole territory
  a1 <- runif(n, 0, 1000)
  a2 <- runif(n, 0, 1000)
  # series_MC$x <- runif(n, 0, 1000)
  # series_MC$y <- runif(n, 0, 1000)
  # append()
  series_MC <- series_MC %>% add_column(x = a1, y = a2)
  col_names <- append(col_names, c(x, y))
}
colnames(series_MC) <- col_names
```

```{r}
# Calculation of rho function for each pair (x,y)
rho_MC <- data.frame(x.1 = rep(0, n), y.1 = rep(0, n))
col_names <- c()
```

```{r}
for (c in 1:B) {
  col_ <- paste("est", c, sep = "")
  # With normalized ratio
  a <- f_x(series_MC[(2*c)-1],series_MC[2*c])
  rho_MC <- rho_MC %>% add_column(col_ = a)
  col_names <- append(col_names, col_)
}
rho_MC$x.1 <- NULL
rho_MC$y.1 <- NULL
colnames(rho_MC) <- col_names
```

```{r}
# List of estimated totals thus obtained from each sample
est_MC <- c()
```

```{r}
for (c in 1:B) {
  est_tot <- sum((rho_MC[c])/p)
  est_MC <- append(est_MC, est_tot)
}
```

```{r}
# Empirical mean based on MC
mean(est_MC) # should be close to 5e+08
# 499121662 e.g.
```

```{r}
# Empirical standard deviation based on MC
sd(est_MC)
```

## Automation of the MC method with a function

```{r}
### Function to automate Monte Carlo method

true_vs_MC <- function(n, B, f, true_value){
  # n: sample size; B: number of iterations for MC; f: function to consider (with 2 variables, x and y)
  p <- sum(rep((1/1000)*(1/1000), n))
  
  # 1st step: generating n samples
  series_MC <- data.frame(x.1 = runif(n, 0, 1000), y.1 = runif(n, 0, 1000))
  col_names <- c("x1", "y1")
  for (b in 2:B) {
    x <- paste("x", b, sep = "")
    y <- paste("y", b, sep = "")
    # Uniform sampling over the whole territory
    a1 <- runif(n, 0, 1000)
    a2 <- runif(n, 0, 1000)
    series_MC <- series_MC %>% add_column(x = a1, y = a2)
    col_names <- append(col_names, c(x, y))
  }
  colnames(series_MC) <- col_names
  
  # 2nd step: creating the values corresponding to the function
  rho_MC <- data.frame(x.1 = rep(0, n), y.1 = rep(0, n))
  col_names <- c()
  for (c in 1:B) {
    col_ <- paste("est", c, sep = "")
    a <- f(series_MC[(2*c)-1],series_MC[2*c])
    rho_MC <- rho_MC %>% add_column(col_ = a)
    col_names <- append(col_names, col_)
  }
  rho_MC$x.1 <- NULL
  rho_MC$y.1 <- NULL
  colnames(rho_MC) <- col_names
  
  # 3rd step: List of estimated totals thus obtained from each sample
  est_MC <- c()
  for (c in 1:B) {
    est_tot <- sum((rho_MC[c])/p)
    est_MC <- append(est_MC, est_tot)
  }
  
  est_value <- mean(est_MC) # Estimated value
  return(c(true_value, est_value))
}
```

```{r}
res <- true_vs_MC(n = 1000, B = 1000, f = fun1, true_value = 1e+06)
cat("True integral:", res[1], "\nMean of all the estimations:", res[2])
# 1e+06 1e+06 (Equality = great)
```

```{r}
res <- true_vs_MC(n = 1000, B = 1000, f = f_ind, true_value = 500000)
cat("True integral:", res[1], "\nMean of all the estimations:", res[2])
# True integral: 5e+05
# Mean of all the estimations: 499600
```

```{r}
res <- true_vs_MC(n = 1000, B = 1000, f = f_x, true_value = 5e+08)
cat("True integral:", res[1], "\nMean of all the estimations:", res[2])

#True integral: 5e+08
# Mean of all the estimations: 500189987
```




---
title: "Monte Carlo and bootstrap for ALL parameters"
output: pdf_document
date: "2024-08-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The goal of this document is to create a large number of Monte Carlo iterations to produce estimators (for the number of trees, the volume of trees, the ratio volume of trees / number of trees and \textbf{other ratios}) and variances of these estimators. The same elements, along with confidence intervals, are also computed for each bootstrap series derived from a smaller number of Monte Carlo iterations. By comparing the two results, we may ensure the validity of the bootstrap strategy to find the estimation of the variances. We may also compare the coverage rates of each type of confidence interval.


In this document, \textbf{uniform sampling} is used to create a sample and \textbf{one single circle} with a radius of 5 is used to compute local variables.

```{r}
library(readxl) # to read the initial file
library(magrittr) # for pipes
library(tibble) # for add_column
```

# Preliminaries

```{r}
# Importing the database with the artificial forest
all_trees <- read_excel("~/work/Sim_article2024/Data/artificial_forest_round.xls")
# To get closer to the NFI process, trees whose circumference is under 23.5 cm are not considered
trees <- all_trees[(pi*all_trees$d130 > 23.5),]
```

```{r}
# Functions to produce a local variable
source("~/work/Sim_article2024/Useful_functions/Circle.R")
```

```{r}
# Sample size
n <- 1000
```

```{r}
# True values
cat("True integrals are the following:\n\nNumber of trees:", nrow(trees), "\nTotal volume:", sum(trees$v), 
    "\nWhich leads to the following ratio \"Total volume / Number of trees\":", sum(trees$v)/nrow(trees),
    "\n\nNumber of small trees:", nrow(trees[(pi*trees$d130 < 70.5),]), "\nVolume of small trees:", sum(trees[(pi*trees$d130 < 70.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 < 70.5),]$v)/nrow(trees[(pi*trees$d130 < 70.5),]),
    "\n\nNumber of medium trees:", nrow(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]), "\nVolume of medium trees:", sum(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]$v)/nrow(trees[(pi*trees$d130 < 117.5) & (pi*trees$d130 > 70.5),]),
    "\n\nNumber of big trees:", nrow(trees[(pi*trees$d130 > 117.5),]), "\nVolume of big trees:", sum(trees[(pi*trees$d130 > 117.5),]$v), 
    "\nWhich leads to the following ratio \"Volume / Number of trees\":", sum(trees[(pi*trees$d130 > 117.5),]$v)/nrow(trees[(pi*trees$d130 > 117.5),])
    )
```

# Monte Carlo alone

10 000 Monte Carlo iterations are appropriated.

```{r}
### Function to automate Monte Carlo method

MonteCarlo <- function(n, B){
  # n: sample size;
  # B: number of iterations for MC
  
  p <- sum(rep((1/1000)*(1/1000), n)) # inclusion density
  
  MC_df <- data.frame(useless = rep(0, n))
  MC_est <- data.frame(useless = rep(0, 3), row.names = c("est_nb", "est_vol", "est_ratio"))
  
  for (b in 1:B) { # All in one "for" loop
    # Uniform sampling over the whole territory
    a1 <- runif(n, 0, 1000)
    a2 <- runif(n, 0, 1000)
    # Variables of interest derived from the sample
    var <- mapply(circle_ALL_, a1, a2)
    MC_b <- data.frame(x = a1, y = a2, z = t(var)[,1], t = t(var)[,2])
    MC_df <- cbind(MC_df, MC_b)
    colnames(MC_df)[(4*(b-1)+2):(4*(b-1)+2+3)] <- c(paste("x", b, sep = ""), paste("y", b, sep = ""), paste("nb", b, sep = ""), paste("vol", b, sep = ""))
    est_b <- t(data.frame(x = sum(MC_df[4*(b-1)+2+2] /p), y = sum(MC_df[4*(b-1)+2+3] /p), z = (sum(MC_df[4*(b-1)+2+3] /p))/(sum(MC_df[4*(b-1)+2+2]/p))))
    MC_est <- cbind(MC_est, est_b)
    colnames(MC_est)[b+1] <- paste("ech", b, sep = "") 
  }
  MC_df$useless <- NULL
  MC_est$useless <- NULL
  MC_var <- c(var(as.vector(t(MC_est[1,]))), var(as.vector(t(MC_est[2,]))), var(as.vector(t(MC_est[3,]))))
  
  return(list(`Local Variables` = MC_df, Estimations = MC_est, Variances = MC_var))
  # Local Variables: local variables (number and volume) for each point in each sample
  # Estimations: 3 estimations (number, volume, ratio volume / number) for each sample
  # Variances: Monte Carlo variance for each of the totals / ratio
}
```

# Bootstrap for each Monte Carlo iteration

1 000 Monte Carlo iterations and 400 bootstrap iterations for each one are appropriated.

```{r}
## BCa nonparametric
# Largely based on the code given in https://gitlab.com/scottkosty/bootstrap/-/blob/master/R/bcanon.R
# Function explained in Efron and Tibshirani (1993)
# Adapted for our particular problem
bcanon <- function(df_init,est_init,est_boot_val,p,...,alpha =
                     c(.025,.975)) { 
    # df_init: initial sample
    # est_init: estimation made thanks to the initial sample
    # est_boot_val: estimations made thanks to bootstrap samples
    # p: inclusion density
    
    nboot <- nrow(est_boot_val)
    thetastar <- as.data.frame(mapply(sort, est_boot_val))
    
    z0 <- mapply(function(one, long){qnorm(sum(long<one)/nboot)}, t(est_init),est_boot_val)
    
    u <- data.frame(x = numeric(), y = numeric())
    for(i in 1:n){
        x_i <- df_init[-i,]
        u <- rbind(u, c(sum(x_i[3]/p), sum(x_i[4]/p)))
    }
    u <- cbind(u, mapply(function(x,y){x/y}, u[2], u[1]))
    uu <- as.data.frame( mapply(function(some_vec){mean(some_vec)-some_vec}, u) )
    acc <- mapply(function(some_vec){sum(some_vec**3)/(6*(sum(some_vec**2))^1.5)}, uu)
    
    zalpha <- qnorm(alpha)
    
    tt <- as.data.frame( mapply(function(z0, acc){pnorm(z0+ (z0+zalpha)/(1-acc*(z0+zalpha)))}, z0, acc) )
    
    confpoints <- as.data.frame( mapply(function(tt, thetastar){quantile(x=thetastar,probs=tt,type=1)}, tt, thetastar) )
    rownames(confpoints) <- NULL
    return(confpoints)
}
```

```{r}
## Making of bootstrap samples based on an initial sample
f_boot <- function(df_sample, B){
  # df_sample: initial sample with 4 variables and of size n; 
  # B: number of bootstrap samples made thanks to df_sample
  
  df_boot <- data.frame(useless = rep(0, nrow(df_sample)-1))
  for (b in 1:B) {
    nb <- sample(1:nrow(df_sample), (nrow(df_sample)-1), replace = TRUE)
    # (n-1) points at random
    sample_b <- df_sample[nb,]
    df_boot <- cbind(df_boot, sample_b)
    colnames(df_boot)[((b-1)*4+1 + 1):(b*4+1)] <- c(paste("ech", b, colnames(df_sample)[1], sep = ""), paste("ech", b, colnames(df_sample)[2], sep = ""), paste("ech", b, colnames(df_sample)[3], sep = ""), paste("ech", b, colnames(df_sample)[4], sep = ""))
  }
  df_boot$useless <- NULL
  return(df_boot)
  # Return a data frame with B samples of 4 variables and of size (n-1)
}
```

```{r}
## Making of estimations for each sample made by the bootstrap method
est_boot <- function(df, p){
  # df: data frame with 4*B columns and (n-1) rows
  # p: inclusion density function (constant in the uniform case)
  
  n <- nrow(df) + 1 # sample size of the initial sample
  nboot <- length(df)/4 # number of bootstrap samples
  vec_est1 <- c()
  vec_est2 <- c()
  vec_est3 <- c()
  for (c in 1:nboot) {
    vec_est1 <- append(vec_est1, (n/(n-1))*sum(df[,3 + (4*(c-1))]/p))
    vec_est2 <- append(vec_est2, (n/(n-1))*sum(df[,4*c]/p))
    vec_est3 <- append(vec_est3, ((n/(n-1))*sum(df[,4*c]/p))/((n/(n-1))*sum(df[,3 + (4*(c-1))]/p)))
    # (n/(n-1)) is the correction needed since we choose only (n-1) points
  }
  vec_est <- data.frame(est_nb = vec_est1, est_vol = vec_est2, est_ratio = vec_est3)
  return(vec_est)
  # Data frame with 3 estimations for each sample
}
```

```{r}
### Function to automate Monte Carlo + bootstrap method

MC_boot <- function(n, B1, B2){
  # n: sample size;
  # B1: number of iterations for MC;
  # B2: number of iterations for bootstrap
  
  p <- sum(rep((1/1000)*(1/1000), n))
  BOOT_df <- list() # All local variables
  BOOT_est <- list() # All estimations
  BOOT_var <- list() # Variances
  BOOT_CI <- list() # Confidence Intervals
  for (b in 1:B1) { # One MC iteration at a time
    # Uniform sampling over the whole territory
    a1 <- runif(n, 0, 1000)
    a2 <- runif(n, 0, 1000)
    var <- mapply(circle_ALL_, a1, a2)
    df_b <- data.frame(x = a1, y = a2, z = t(var)[,1], t = t(var)[,2])
    colnames(df_b) <- c(paste("x.MC", b, sep = ""), paste("y.MC", b, sep = ""), paste("nb.MC", b, sep = ""), paste("vol.MC", b, sep = ""))
    est_b <- t(data.frame(x = sum(df_b[3] /p), y = sum(df_b[4] /p), z = (sum(df_b[4] /p))/(sum(df_b[3]/p))))
    
    # Bootstrap iterations
    df_boot <- f_boot(df_b, B2)
    est_boot_val <- est_boot(df_boot, p)
    
    BOOT_var[[b]] <- list(var_nb = var(est_boot_val$est_nb), var_vol = var(est_boot_val$est_vol), var_ratio = var(est_boot_val$est_ratio))
    names(BOOT_var)[b] <- paste("Variance", b, sep = "")
    BOOT_df <- c(BOOT_df, list(data_init = df_b, data_boot = df_boot))
    names(BOOT_df)[(2*b-1):(2*b)] <- c(paste("df_MC", b, sep = ""), paste("df_boot", b, sep = ""))
    BOOT_est <- c(BOOT_est, list(est_init_b = est_b, est_boot_b = est_boot_val))
    names(BOOT_est)[(2*b-1):(2*b)] <- c(paste("est_MC", b, sep = ""), paste("est_boot", b, sep = ""))
    
    # Confidence intervals
    norm_CI <- data.frame(useless = rep(0, 2))
    perc_CI <- data.frame(useless = rep(0, 2))
    rev_perc_CI <- data.frame(useless = rep(0, 2))
    for (l in 1:3) { # Loop: one estimator each time
      sorted_est <- sort(est_boot_val[,l])
      lim_inf <- sorted_est[floor(B2*2.5/100)]
      lim_sup <- sorted_est[B2 - floor(B2*2.5/100)]
      perc_CI <- cbind(perc_CI, data.frame(c(lim_inf, lim_sup)))
      rev_perc_CI <- cbind(rev_perc_CI, data.frame(c(est_b[l,]*2 - lim_sup, est_b[l,]*2 - lim_inf)))
      norm_CI <- cbind(norm_CI, data.frame(c(est_b[l,]-qnorm(0.975)*sqrt(var(est_boot_val[,l])), est_b[l,]+qnorm(0.975)*sqrt(var(est_boot_val[,l])))))
    }
    norm_CI$useless <- NULL
    perc_CI$useless <- NULL
    rev_perc_CI$useless <- NULL
    colnames(norm_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    colnames(perc_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    colnames(rev_perc_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    BCa_CI <- bcanon(df_b, est_b, est_boot_val,p)
    colnames(BCa_CI) <- c("lim_nb", "lim_vol", "lim_ratio")
    all_CI <- list(Normal = norm_CI, Percentile = perc_CI, `Reverse percentile` = rev_perc_CI, BCa = BCa_CI)
    BOOT_CI[[b]] <- all_CI
    names(BOOT_CI)[b] <- paste("CI", b, sep = "")
  }
  return(list(`Local Variables` = BOOT_df, Estimations = BOOT_est, Variances = BOOT_var, `Confidence Intervals` = BOOT_CI))
  # Local Variables: local variables (number and volume) for each point in each sample
  # Estimations: 3 estimations (number, volume, ratio volume / number) for each sample
  # Variances: mean of the bootstrap variance for each estimator
  # Confidence Intervals: 3 different forms of 95% confidence intervals, for each total / ratio
}
```

# Example

## Monte Carlo alone

```{r}
start.time <- Sys.time()

res1 <- MonteCarlo(n, 10000)
# Just one circle to begin with

end.time <- Sys.time()
time.taken <- end.time - start.time

time.taken
```

```{r}
cat("Monte Carlo means of estimations: \n - for the number of trees:", mean(as.vector(t(res1$Estimations[1,]))), "\n - for the volume of trees:", mean(as.vector(t(res1$Estimations[2,]))), "\n - for the ratio volume / number of trees:", mean(as.vector(t(res1$Estimations[3,]))))

# Example:
```

```{r}
cat("Monte Carlo variances: \n - for the number of trees:", res1$Variances[1], "\n - for the volume of trees:", res1$Variances[2], "\n - for the ratio volume / number of trees:", res1$Variances[3])

# Example:
```

## Monte Carlo and bootstrap

```{r}
start.time <- Sys.time()

res2 <- MC_boot(n, B1 = 1000, B2 = 400)
# Just one circle to begin with

end.time <- Sys.time()
time.taken <- end.time - start.time

time.taken
```

```{r}
# We want all the variances obtained for each parameter of interest, 
# to find the mean for each of these series
EST_nb <- c()
EST_vol <- c()
EST_ratio <- c()
for (elt in res2$Estimations) {
  if ("data.frame" %in% class(elt)){ # we target bootstrap samples made from each MC iteration
    EST_nb <- append(EST_nb, mean(elt$est_nb))
    EST_vol <- append(EST_vol, mean(elt$est_vol))
    EST_ratio <- append(EST_ratio, mean(elt$est_ratio))
  }
}
```

```{r}
cat("Mean of the means of estimations obtained through each bootstrap process:\n - for the number of trees:", mean(EST_nb), "\n - for the volume of trees:", mean(EST_vol), "\n - for the ratio volume / number of trees:", mean(EST_ratio))

# Example:
```

```{r}
# We want all the variances obtained for each parameter of interest, 
# to find the mean for each of these series
VAR_nb <- c()
VAR_vol <- c()
VAR_ratio <- c()
for (elt in res2$Variances) {
  VAR_nb <- append(VAR_nb, elt$var_nb)
  VAR_vol <- append(VAR_vol, elt$var_vol)
  VAR_ratio <- append(VAR_ratio, elt$var_ratio)
}
```

```{r}
cat("Mean of the variance of bootstrap samples:\n - for the number of trees:", mean(VAR_nb), "\n - for the volume of trees:", mean(VAR_vol), "\n - for the ratio volume / number of trees:", mean(VAR_ratio))

# Example:
```

```{r}
coverage_rate <- function(k){
  CI_nb <- data.frame(useless = c(0,0))
  CI_vol <- data.frame(useless = c(0,0))
  CI_ratio <- data.frame(useless = c(0,0))
  for (elt in res2$`Confidence Intervals`) {
    CI_nb <- cbind(CI_nb, c(unlist(elt[k])[1], unlist(elt[k])[2]))
    CI_vol <- cbind(CI_vol, c(unlist(elt[k])[3], unlist(elt[k])[4]))
    CI_ratio <- cbind(CI_ratio, c(unlist(elt[k])[5], unlist(elt[k])[6]))
  }
  CI_nb$useless <- NULL
  CI_vol$useless <- NULL
  CI_ratio$useless <- NULL
  
  CI_nb <- as.data.frame(t(CI_nb))
  CI_vol <- as.data.frame(t(CI_vol))
  CI_ratio <- as.data.frame(t(CI_ratio))
  
  # Coverage rate
  TC_nb <- (1/nrow(CI_nb))*sum( mapply(function(a,b){as.numeric((29272 > a) & (29272 < b))}, CI_nb[1], CI_nb[2]) )
  TC_vol <- (1/nrow(CI_vol))*sum( mapply(function(a,b){as.numeric((5412.722 > a) & (5412.722 < b))}, CI_vol[1], CI_vol[2]) )
  TC_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a,b){as.numeric((0.1849112 > a) & (0.1849112 < b))}, CI_ratio[1], CI_ratio[2]) )
  
  # Lower tail
  low_tail_nb <- (1/nrow(CI_nb))*sum( mapply(function(a){as.numeric(29272 < a)}, CI_nb[1]) )
  low_tail_vol <- (1/nrow(CI_vol))*sum( mapply(function(a){as.numeric(5412.722 < a)}, CI_vol[1]) )
  low_tail_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(a){as.numeric(0.1849112 < a)}, CI_ratio[1]) )
  
  # Upper tail
  up_tail_nb <- (1/nrow(CI_nb))*sum( mapply(function(b){as.numeric(29272 > b)}, CI_nb[2]) )
  up_tail_vol <- (1/nrow(CI_vol))*sum( mapply(function(b){as.numeric(5412.722 > b)}, CI_vol[2]) )
  up_tail_ratio <- (1/nrow(CI_ratio))*sum( mapply(function(b){as.numeric(0.1849112 > b)}, CI_ratio[2]) )
  
  # Mean length of CIs
  length_nb <- mean( mapply(function(a,b){b-a}, CI_nb[1], CI_nb[2]) )
  length_vol <- mean( mapply(function(a,b){b-a}, CI_vol[1], CI_vol[2]) )
  length_ratio <- mean( mapply(function(a,b){b-a}, CI_ratio[1], CI_ratio[2]) )
  
  df_TC <- data.frame(TC = c(TC_nb, TC_vol, TC_ratio), Upper = c(low_tail_nb, low_tail_vol, low_tail_ratio), Lower = c(up_tail_nb, up_tail_vol, up_tail_ratio), Mean_length = c(length_nb, length_vol, length_ratio))
  
  return(df_TC)
}
```

```{r}
TC_normal <- coverage_rate(1)
cat("Concerning the normal approach, the coverage rates are the following: \n - for the number of trees: ", 
    TC_normal[1,1], "\n - for the volume of trees: ", TC_normal[2,1], "\n - for the ratio volume / number of trees: ", TC_normal[3,1],
    " \n\nThe parts of the estimators under the lower limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_normal[1,2], "\n - for the volume of trees: ", TC_normal[2,2], "\n - for the ratio volume / number of trees: ", TC_normal[3,2],
    " \n\nThe parts of the estimators over the upper limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_normal[1,3], "\n - for the volume of trees: ", TC_normal[2,3], "\n - for the ratio volume / number of trees: ", TC_normal[3,3],
    " \n\nThe mean lengths of coverage rates are the following: \n - for the number of trees: ",
    TC_normal[1,4], "\n - for the volume of trees: ", TC_normal[2,4], "\n - for the ratio volume / number of trees: ", TC_normal[3,4])
```

```{r}
TC_perc <- coverage_rate(2)
cat("Concerning the percentile approach, the coverage rates are the following: \n - for the number of trees: ", 
    TC_perc[1,1], "\n - for the volume of trees: ", TC_perc[2,1], "\n - for the ratio volume / number of trees: ", TC_perc[3,1],
    " \n\nThe parts of the estimators under the lower limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_perc[1,2], "\n - for the volume of trees: ", TC_perc[2,2], "\n - for the ratio volume / number of trees: ", TC_perc[3,2],
    " \n\nThe parts of the estimators over the upper limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_perc[1,3], "\n - for the volume of trees: ", TC_perc[2,3], "\n - for the ratio volume / number of trees: ", TC_perc[3,3],
    " \n\nThe mean lengths of coverage rates are the following: \n - for the number of trees: ",
    TC_perc[1,4], "\n - for the volume of trees: ", TC_perc[2,4], "\n - for the ratio volume / number of trees: ", TC_perc[3,4])
```

```{r}
TC_rev_perc <- coverage_rate(3)
cat("Concerning the reverse percentile approach, the coverage rates are the following: \n - for the number of trees: ", 
    TC_rev_perc[1,1], "\n - for the volume of trees: ", TC_rev_perc[2,1], "\n - for the ratio volume / number of trees: ", TC_rev_perc[3,1],
    " \n\nThe parts of the estimators under the lower limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_rev_perc[1,2], "\n - for the volume of trees: ", TC_rev_perc[2,2], "\n - for the ratio volume / number of trees: ", TC_rev_perc[3,2],
    " \n\nThe parts of the estimators over the upper limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_rev_perc[1,3], "\n - for the volume of trees: ", TC_rev_perc[2,3], "\n - for the ratio volume / number of trees: ", TC_rev_perc[3,3],
    " \n\nThe mean lengths of coverage rates are the following: \n - for the number of trees: ",
    TC_rev_perc[1,4], "\n - for the volume of trees: ", TC_rev_perc[2,4], "\n - for the ratio volume / number of trees: ", TC_rev_perc[3,4])
```

```{r}
TC_bca <- coverage_rate(4)
cat("Concerning the BCa approach, the coverage rates are the following: \n - for the number of trees: ", 
    TC_bca[1,1], "\n - for the volume of trees: ", TC_bca[2,1], "\n - for the ratio volume / number of trees: ", TC_bca[3,1],
    " \n\nThe parts of the estimators under the lower limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_bca[1,2], "\n - for the volume of trees: ", TC_bca[2,2], "\n - for the ratio volume / number of trees: ", TC_bca[3,2],
    " \n\nThe parts of the estimators over the upper limit of the coverage rate are the following: \n - for the number of trees: ",
    TC_bca[1,3], "\n - for the volume of trees: ", TC_bca[2,3], "\n - for the ratio volume / number of trees: ", TC_bca[3,3],
    " \n\nThe mean lengths of coverage rates are the following: \n - for the number of trees: ",
    TC_bca[1,4], "\n - for the volume of trees: ", TC_bca[2,4], "\n - for the ratio volume / number of trees: ", TC_bca[3,4])
```

## Comparison of the variances

```{r}
diff_percent <- function(x,y)100*(max(x,y)-min(x,y))/min(x,y)
cat("Difference between the two estimations of variance: \n - for the number of trees: ", diff_percent(res1$Variances[1], mean(VAR_nb)), "%", "\n - for the volume of trees: ", diff_percent(res1$Variances[2], mean(VAR_vol)), "%\n - for the ratio volume / number of trees: ", diff_percent(res1$Variances[3], mean(VAR_ratio)), "%", sep = "")

# Example:
```
